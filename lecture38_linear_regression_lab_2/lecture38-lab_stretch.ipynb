{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression + Timeseries\n",
    "For this mini-lab, you will learn a bit about how to use linear regression to fit _filters_ that you can use to model timeseries. You'll be using linear regression techniques to model fMRI responses to video stimuli (the ones that we've talked about in class) based on the presence of two categories in the videos: people and buildings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ybig_trn', 'X_test', 'X_trn', 'y_trn', 'ybig_test', 'y_test']\n"
     ]
    }
   ],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Load the fMRI dataset\n",
    "datafile = np.load('data.npz')\n",
    "\n",
    "# list all the variables in the file\n",
    "print(datafile.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the data\n",
    "# (you don't need to worry about subtracting the mean later because that's done here)\n",
    "\n",
    "# the features (X) say whether people (column zero) or buildings (column one) are present in each video clip\n",
    "X_trn = datafile['X_trn'] # time x features\n",
    "X_trn -= X_trn.mean(0) # subtract the mean over time\n",
    "X_test = datafile['X_test'] # time x features\n",
    "X_test -= X_test.mean(0) # ditto\n",
    "\n",
    "# y_trn and y_test have the fMRI response of one voxel\n",
    "y_trn = datafile['y_trn'] # time\n",
    "y_trn -= y_trn.mean(0)\n",
    "y_test = datafile['y_test'] # time\n",
    "y_test -= y_test.mean(0)\n",
    "\n",
    "# ybig_trn and ybig_test have the response of 10,000 voxels\n",
    "ybig_trn = datafile['ybig_trn']\n",
    "ybig_trn -= ybig_trn.mean(0)\n",
    "ybig_test = datafile['ybig_test']\n",
    "ybig_test -= ybig_test.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the size of each array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the regression target (y) and each of the features\n",
    "Step 1 in any analysis should _always_ be to **LOOK AT YOUR DATA**. Let's plot it and see what it looks like: what's the range, does it look uniform, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot y_trn, X_trn[:,0], and X_trn[:,1] on the same axis. do you see anything?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the correlation between X_trn[:,0] and y_trn (ditto for X_trn[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a histogram of y_trn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Finite Impulse Response (FIR) Regression Model\n",
    "One of the key things you should know about fMRI is that it measures the Blood-Oxygen-Level Dependent (BOLD) signal, which tells you about blood flow in each area of the brain. This signal doesn't directly track neural activity! After there is a burst of neural activity in an area, nearby blood vessels slowly respond and recruit more blood over the next 2-8 seconds. So we can't directly model the fMRI response with our stimuli! We need to account for the slow [hemodynamic response](https://en.wikipedia.org/wiki/Haemodynamic_response).\n",
    "\n",
    "We can think of the hemodynamic response as (to first approximation) a _filter_ on the underlying neural activity. So if the stimulus features (here, the presence of people or buildings in a video) is correlated with the neural activity, we can try to find a filter that we can apply to the stimulus features in order to make them look like the response.\n",
    "\n",
    "We'll do this by creating new features that are _lagged_ versions of the stimulus features. If we use lags (1,2,3,4) then it's like we're modeling the response $y_t$ as a function of the stimulus features $x_{t-1}, x_{t-2}, x_{t-3}, x_{t-4}$. This is just like fitting a filter that is (effectively) convolved with the stimulus feature to get the response!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's start with just one feature, feature zero\n",
    "# create a matrix that will hold 4 lagged feature vectors\n",
    "X_trn_lagged = np.zeros((###SOMETHING###))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now copy the feature X_trn[:,0] into each of the 4 columns of your new matrix\n",
    "# we want the first column to be lagged by 1 timepoint relative to the original,\n",
    "# the second is lagged 2, etc.\n",
    "\n",
    "for ii,lag in enumerate([1,2,3,4]):\n",
    "    # `frm` should be the timepoint that you start copying from in X_trn\n",
    "    frm = ## SOMETHING ##\n",
    "    # and `to` is the last timepoint\n",
    "    to = ## SOMETHING\n",
    "    X_trn_lagged[lag:,ii] = X_trn[frm:to,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot each of these 4 feature vectors on the same plot here to make sure they look right\n",
    "# they should look identical, but shifted in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now do the same thing to create X_val_lagged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model!\n",
    "Next, use `np.linalg.lstsq` to fit a linear regression model that predicts `y_trn` from `X_trn_lagged`. Save the `wt, rank, res, sing` as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do regression here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now plot the weights as dots connected by lines. what do these weights mean? why do they look like that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model!\n",
    "Use the dot product between `wt` and `X_val_lagged` to predict responses in the test dataset, then compute the correlation between them. How well does our model work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create predicted test timecourse\n",
    "y_test_pred = ## SOMETHING ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute correlation\n",
    "model1_corr = ## SOMETHING ##\n",
    "print(model1_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat the modeling procedure for every voxel in the `ybig_*` dataset\n",
    "The model above was fit to just one voxel. Let's repeat this process for each of the 10,000 voxels in the bigger dataset. Ideally we would do this by reshaping the `ybig_*` datasets into a more sensible shape, but it might be easier to do using a for-loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_big = np.zeros((4, 100, 100))\n",
    "for ii in range(100):\n",
    "    for jj in range(100):\n",
    "        ## SOMETHING ##\n",
    "        wt_big[:,ii,jj] = ## SOMETHING ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute predictions & find the prediction correlation for every voxel in the big set\n",
    "corr_big = np.zeros((100,100))\n",
    "for ii in range(100):\n",
    "    for jj in range(100):\n",
    "        corr_big[ii,jj] = ## SOMETHING ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the correlations using plt.matshow. \n",
    "# this shows correlation across one axial slice through a subject's brain. what do you see?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
