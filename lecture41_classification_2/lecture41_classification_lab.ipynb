{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification for fMRI decoding\n",
    "\n",
    "In this lab you're going to use a classifier (logistic regression) to decode the presence of one category (human faces) from fMRI responses to a natural movie stimulus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model, metrics\n",
    "\n",
    "# Load the fMRI dataset\n",
    "datafile = np.load('../lecture38_linear_regression_lab_2/data.npz')\n",
    "\n",
    "# list all the variables in the file\n",
    "print(datafile.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the data\n",
    "# (you don't need to worry about subtracting the mean later because that's done here)\n",
    "\n",
    "# the stimulus features say whether people (column zero) or buildings (column one) are present in each video clip\n",
    "stim_trn = datafile['X_trn']>0 # time x features\n",
    "#stim_trn -= stim_trn.mean(0) # subtract the mean over time\n",
    "stim_test = datafile['X_test']>0 # time x features\n",
    "#stim_test -= stim_test.mean(0) # ditto\n",
    "\n",
    "\n",
    "# resp_trn and resp_test have the response of 10,000 voxels\n",
    "resp_trn = np.nan_to_num(datafile['ybig_trn'].reshape((1200,-1)))\n",
    "resp_trn -= resp_trn.mean(0)\n",
    "resp_trn = np.roll(resp_trn, -2, 0)\n",
    "\n",
    "resp_test = np.nan_to_num(datafile['ybig_test'].reshape((90,-1)))\n",
    "resp_test -= resp_test.mean(0)\n",
    "resp_test = np.roll(resp_test, -2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the shapes of stim_trn, stim_test, resp_trn, and resp_test\n",
    "# make sure you know what each dimension means!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot the first column of stim_trn\n",
    "# label the x- and y-axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "Next you're going to create & fit a logistic regression model. This model will learn a linear weight for each voxel in the response dataset to try to classify whether each timepoint contains the given category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a LogisticRegressionCV object\n",
    "# set the parameter `verbose=1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model using resp_trn to predict the first column of stim_trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict whether faces are present on the test dataset, resp_test\n",
    "# use the method `predict_proba`, which gives you continuous values\n",
    "# that correspond to the predicted probability of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the shape of `pred`\n",
    "# it has 2 columns, which contain the probability of `False` and the probability of `True`\n",
    "# i.e. the probability that the stimulus did not contain a face, and the probability that it did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the predicted probability of face being present across time (the 2nd column of `pred`)\n",
    "# also plot the actual presence of faces (the first column of stim_test)\n",
    "# label your x- and y-axes\n",
    "# make the plot pretty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC Analysis\n",
    "\n",
    "Next you're going to do a receiver operating characteristic (ROC) analysis to test how well your classifier works. ROC analysis works by testing the false positive rate (fpr) and true positive rate (tpr) for different thresholds on the predicted probability. False positive rate measures how often a real `False` (a stimulus that did not contain a face) is labeled as containing a face by the classifier (at the given threshold). True positive rate measures how often a real `True` (a stimulus that _did_ contain a face) is labeled as such at the given threshold. The ROC curve is a plot of fpr vs. tpr for every possible threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the function `metrics.roc_curve` to do the ROC analysis\n",
    "# give it the real stimulus values (first column of stim_test)\n",
    "# and the predicted probabilities (second column of pred)\n",
    "# store the outputs as fpr, tpr, thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the ROC curve\n",
    "# first create a square plot using plt.figure with figsize=(6,6)\n",
    "# then plot the roc curve (fpr on x-axis, tpr on y-axis)\n",
    "# then plot a diagonal line (x=0,y=0 to x=1,y=1) for reference\n",
    "# label the x- and y-axes\n",
    "# then interpret the plot. how does it look? is it good?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next let's compute the area under the ROC curve\n",
    "# this is a metric that's often used to say how well a classifier works\n",
    "# you can use the function `np.trapz` to do integration using the trapezoidal rule\n",
    "auc = ## SOMETHING ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examining classifier weights\n",
    "Next let's look at the classifier weights to see which parts of the brain were used here. The 10,000 voxels that we used to fit the classifier all come from one slice (with size 100 x 100) in an fMRI scan. So let's take the weights (called `logistic_model.coef_`), reshape them back to (100x100), and then plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the coefs using the .reshape method of a numpy array\n",
    "# the coefs should be logistic_model.coef_[0]\n",
    "# and the final shape should be (100,100)\n",
    "reshaped_coefs = ## SOMETHING ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next plot the coefs using matshow\n",
    "# also add a colorbar\n",
    "# what do these values mean? what does it mean to have a positive weight vs. negative weight?\n",
    "# how can we interpret these weights?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just looking at the coefs directly is tricky because it's missing anatomical information\n",
    "# we can get some of that by looking at the std of resp_test\n",
    "# (which only has high std in cortical voxels)\n",
    "\n",
    "# compute the std of resp_test over its time dimension (axis 0), and reshape the result to (100,100)\n",
    "# then plot that using plt.matshow with a gray colormap (`cmap='gray'`)\n",
    "\n",
    "# next create a thresholded version of `reshaped_coefs`\n",
    "# first create a copy of `reshaped_coefs` called `coefs_thresh`\n",
    "\n",
    "# then set all the values in `coefs_thresh` below some threshold (try 0.02 to start) to np.nan\n",
    "\n",
    "# finally plot coefs_thresh on top of the grayscale anatomical map using plt.imshow\n",
    "# use the parameters `interpolation='nearest'`, a colormap like `cmap='Reds'`, and `vmin=0`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat test for the other category\n",
    "Go back to the section titled \"Logistic Regression\" and change your code so that it's predicting the presence of the other stimulus category (the second column of `stim_trn` and `stim_test`), which tells you whether a building was present in each timepoint.\n",
    "\n",
    "How well does this work? Does it use different voxels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
